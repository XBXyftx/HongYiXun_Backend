# Copyright (c) 2025 XBXyftx
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
51CTOå¼€æºç¤¾åŒºAPIè·¯ç”±
æä¾›æ–‡ç« è·å–ã€æœç´¢ã€åˆ†é¡µç­‰åŠŸèƒ½
"""

from fastapi import APIRouter, Query, HTTPException, BackgroundTasks
from typing import Optional, List
import logging
from datetime import datetime
import threading

from services.cto51_crawler import Cto51Crawler
from models.cto51 import Cto51Article, Cto51Response, Cto51ContentBlock

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/api/cto51", tags=["51cto"])

# å†…å­˜ç¼“å­˜
_cache_lock = threading.RLock()
_article_cache: List[Cto51Article] = []
_cache_status = {
    "last_update": None,
    "is_updating": False,
    "total_articles": 0,
    "error": None
}


def _update_cache_from_dict_list(articles_dict_list: List[dict]):
    """ä»å­—å…¸åˆ—è¡¨æ›´æ–°ç¼“å­˜"""
    global _article_cache, _cache_status

    with _cache_lock:
        try:
            # è½¬æ¢ä¸ºPydanticæ¨¡å‹
            new_articles = []
            for article_dict in articles_dict_list:
                try:
                    # è½¬æ¢content blocks
                    content_blocks = [
                        Cto51ContentBlock(**block) for block in article_dict.get('content', [])
                    ]
                    article_dict['content'] = content_blocks

                    # åˆ›å»ºArticleå¯¹è±¡
                    article = Cto51Article(**article_dict)
                    new_articles.append(article)
                except Exception as e:
                    logger.error(f"âŒ è½¬æ¢æ–‡ç« å¤±è´¥: {e}")
                    continue

            # æ›´æ–°ç¼“å­˜ï¼ˆå»é‡ï¼‰
            existing_ids = {article.id for article in _article_cache}
            for article in new_articles:
                if article.id not in existing_ids:
                    _article_cache.append(article)
                    existing_ids.add(article.id)

            # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            _article_cache.sort(key=lambda x: x.created_at or datetime.now(), reverse=True)

            # æ›´æ–°çŠ¶æ€
            _cache_status["total_articles"] = len(_article_cache)
            _cache_status["last_update"] = datetime.now().isoformat()
            _cache_status["error"] = None

            logger.info(f"âœ… ç¼“å­˜å·²æ›´æ–°ï¼Œå½“å‰å…±æœ‰ {len(_article_cache)} ç¯‡æ–‡ç« ")

        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ç¼“å­˜å¤±è´¥: {e}")
            _cache_status["error"] = str(e)


def _crawl_and_update_cache(max_pages: int = 3):
    """åå°çˆ¬å–å¹¶æ›´æ–°ç¼“å­˜"""
    global _cache_status

    try:
        _cache_status["is_updating"] = True
        logger.info(f"ğŸš€ å¼€å§‹åå°çˆ¬å–51CTOæ–‡ç« ï¼Œæœ€å¤§é¡µæ•°: {max_pages}")

        # åˆ›å»ºçˆ¬è™«
        crawler = Cto51Crawler(headless=True)

        # å®šä¹‰æ‰¹é‡å›è°ƒ
        def batch_callback(articles_batch: List[dict]):
            _update_cache_from_dict_list(articles_batch)

        # æ‰§è¡Œçˆ¬å–
        articles = crawler.crawl_articles(max_pages=max_pages, batch_callback=batch_callback)

        logger.info(f"âœ… åå°çˆ¬å–å®Œæˆï¼Œå…±è·å– {len(articles)} ç¯‡æ–‡ç« ")

    except Exception as e:
        logger.error(f"âŒ åå°çˆ¬å–å¤±è´¥: {e}")
        _cache_status["error"] = str(e)

    finally:
        _cache_status["is_updating"] = False


@router.get("/", response_model=Cto51Response)
async def get_cto51_articles(
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    search: Optional[str] = Query(None, description="æœç´¢å…³é”®è¯"),
    all: bool = Query(False, description="æ˜¯å¦è¿”å›å…¨éƒ¨æ–‡ç« ä¸åˆ†é¡µ")
):
    """
    è·å–51CTOæ–‡ç« åˆ—è¡¨

    å‚æ•°è¯´æ˜ï¼š
    - page: é¡µç ï¼ˆå½“all=Trueæ—¶å¿½ç•¥ï¼‰
    - page_size: æ¯é¡µæ•°é‡ï¼ˆå½“all=Trueæ—¶å¿½ç•¥ï¼‰
    - search: æœç´¢å…³é”®è¯ï¼ˆåœ¨æ ‡é¢˜å’Œæ‘˜è¦ä¸­æœç´¢ï¼‰
    - all: æ˜¯å¦è¿”å›å…¨éƒ¨æ–‡ç« ä¸åˆ†é¡µ
    """
    try:
        with _cache_lock:
            articles = _article_cache.copy()

        # æœç´¢è¿‡æ»¤
        if search:
            search_lower = search.lower()
            articles = [
                article for article in articles
                if (search_lower in article.title.lower()) or
                   (article.summary and search_lower in article.summary.lower())
            ]

        total = len(articles)

        # åˆ†é¡µå¤„ç†
        if all:
            # è¿”å›æ‰€æœ‰æ•°æ®
            return Cto51Response(
                articles=articles,
                total=total,
                page=1,
                page_size=total,
                has_next=False,
                has_prev=False
            )
        else:
            # æ­£å¸¸åˆ†é¡µ
            start = (page - 1) * page_size
            end = start + page_size
            paginated_articles = articles[start:end]

            return Cto51Response(
                articles=paginated_articles,
                total=total,
                page=page,
                page_size=page_size,
                has_next=end < total,
                has_prev=page > 1
            )

    except Exception as e:
        logger.error(f"âŒ è·å–æ–‡ç« åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="è·å–æ–‡ç« åˆ—è¡¨å¤±è´¥")


@router.get("/{article_id}", response_model=Cto51Article)
async def get_cto51_article_detail(article_id: str):
    """
    è·å–å•ç¯‡æ–‡ç« è¯¦æƒ…

    å‚æ•°ï¼š
    - article_id: æ–‡ç« å”¯ä¸€æ ‡è¯†ç¬¦
    """
    try:
        with _cache_lock:
            for article in _article_cache:
                if article.id == article_id:
                    return article

        # æœªæ‰¾åˆ°æ–‡ç« 
        raise HTTPException(status_code=404, detail="æ–‡ç« ä¸å­˜åœ¨")

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ è·å–æ–‡ç« è¯¦æƒ…å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="è·å–æ–‡ç« è¯¦æƒ…å¤±è´¥")


@router.post("/crawl")
async def crawl_cto51_articles(
    background_tasks: BackgroundTasks,
    max_pages: int = Query(3, ge=1, le=10, description="æœ€å¤§çˆ¬å–é¡µæ•°")
):
    """
    æ‰‹åŠ¨è§¦å‘çˆ¬å–51CTOæ–‡ç« 

    å‚æ•°ï¼š
    - max_pages: æœ€å¤§çˆ¬å–é¡µæ•°ï¼ˆ1-10ï¼‰
    """
    try:
        if _cache_status["is_updating"]:
            raise HTTPException(status_code=409, detail="çˆ¬å–ä»»åŠ¡æ­£åœ¨è¿›è¡Œä¸­ï¼Œè¯·ç¨åå†è¯•")

        # æ·»åŠ åå°ä»»åŠ¡
        background_tasks.add_task(_crawl_and_update_cache, max_pages)

        return {
            "message": f"çˆ¬å–ä»»åŠ¡å·²å¯åŠ¨ï¼Œå°†çˆ¬å–æœ€å¤š {max_pages} é¡µ",
            "max_pages": max_pages,
            "timestamp": datetime.now().isoformat(),
            "note": "çˆ¬å–ä»»åŠ¡åœ¨åå°æ‰§è¡Œï¼Œè¯·ç¨åæŸ¥çœ‹ç¼“å­˜çŠ¶æ€"
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ å¯åŠ¨çˆ¬å–ä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="å¯åŠ¨çˆ¬å–ä»»åŠ¡å¤±è´¥")


@router.get("/status/info")
async def get_cto51_status():
    """
    è·å–51CTOæœåŠ¡çŠ¶æ€ä¿¡æ¯
    """
    try:
        with _cache_lock:
            status = _cache_status.copy()

        return {
            "service": "51CTOå¼€æºç¤¾åŒº",
            "cache_status": status,
            "endpoints": {
                "list": "/api/cto51/",
                "detail": "/api/cto51/{article_id}",
                "crawl": "/api/cto51/crawl",
                "status": "/api/cto51/status/info"
            },
            "timestamp": datetime.now().isoformat()
        }

    except Exception as e:
        logger.error(f"âŒ è·å–æœåŠ¡çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="è·å–æœåŠ¡çŠ¶æ€å¤±è´¥")


@router.post("/cache/clear")
async def clear_cto51_cache():
    """
    æ¸…ç©ºç¼“å­˜ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰
    """
    try:
        global _article_cache, _cache_status

        with _cache_lock:
            _article_cache.clear()
            _cache_status["total_articles"] = 0
            _cache_status["last_update"] = None

        return {
            "message": "ç¼“å­˜å·²æ¸…ç©º",
            "timestamp": datetime.now().isoformat()
        }

    except Exception as e:
        logger.error(f"âŒ æ¸…ç©ºç¼“å­˜å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="æ¸…ç©ºç¼“å­˜å¤±è´¥")
