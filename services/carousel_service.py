import asyncio
import time
import logging
import requests
from typing import List, Dict, Any, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from pathlib import Path
import sys
import os
import re

from core.config import settings
from core.logging_config import log_function_call

logger = logging.getLogger(__name__)


@dataclass
class CrawlerConfig:
    """è½®æ’­å›¾çˆ¬è™«é…ç½®"""
    target_url: str
    base_domain: str
    user_agent: str
    viewport_width: int
    viewport_height: int
    device_scale_factor: int
    headless: bool
    timeout: int


class CarouselCrawlerService:
    """åä¸ºè½®æ’­å›¾çˆ¬è™«æœåŠ¡"""

    def __init__(self):
        self.config = CrawlerConfig(
            target_url=getattr(settings, 'huawei_target_url', 'https://developer.huawei.com'),
            base_domain=getattr(settings, 'huawei_base_domain', 'https://developer.huawei.com'),
            user_agent=getattr(settings, 'mobile_user_agent', 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/605.1.15'),
            viewport_width=getattr(settings, 'mobile_viewport_width', 375),
            viewport_height=getattr(settings, 'mobile_viewport_height', 667),
            device_scale_factor=getattr(settings, 'mobile_device_scale_factor', 2),
            headless=getattr(settings, 'browser_headless', True),
            timeout=getattr(settings, 'browser_timeout', 30)
        )
        self.thread_pool = ThreadPoolExecutor(max_workers=2, thread_name_prefix="CarouselCrawler")
        logger.info("ğŸ¯ åä¸ºè½®æ’­å›¾çˆ¬è™«æœåŠ¡åˆå§‹åŒ–å®Œæˆ")

    @log_function_call
    def crawl_carousel_data(self) -> List[Dict[str, Any]]:
        """
        çˆ¬å–åä¸ºè½®æ’­å›¾æ•°æ®ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        """
        start_time = time.time()
        logger.info(f"ğŸš€ å¼€å§‹çˆ¬å–åä¸ºè½®æ’­å›¾æ•°æ®: {self.config.target_url}")

        try:
            # ä½¿ç”¨requestsè·å–é¡µé¢å†…å®¹ï¼ˆç®€åŒ–å®ç°ï¼‰
            response = requests.get(
                self.config.target_url,
                timeout=self.config.timeout,
                headers={
                    "User-Agent": self.config.user_agent,
                    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"
                }
            )

            if response.status_code != 200:
                logger.error(f"âŒ HTTPè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return []

            # è¿™é‡Œåº”è¯¥è§£æé¡µé¢æå–è½®æ’­å›¾æ•°æ®
            # ç”±äºåŸå§‹çˆ¬è™«ä»£ç ä¸å¯ç”¨ï¼Œè¿™é‡Œè¿”å›æ¨¡æ‹Ÿæ•°æ®
            carousel_data = self._generate_mock_data()

            # å¤„ç†å’Œæ ‡å‡†åŒ–æ•°æ®
            processed_data = self._process_carousel_data(carousel_data)

            crawl_duration = time.time() - start_time
            logger.info(f"âœ… è½®æ’­å›¾çˆ¬å–å®Œæˆï¼Œè€—æ—¶: {crawl_duration:.2f}ç§’ï¼Œè·å– {len(processed_data)} æ¡æ•°æ®")

            return processed_data

        except Exception as e:
            crawl_duration = time.time() - start_time
            logger.error(f"âŒ è½®æ’­å›¾çˆ¬å–å¤±è´¥ï¼Œè€—æ—¶: {crawl_duration:.2f}ç§’ï¼Œé”™è¯¯: {e}", exc_info=True)
            return []

    def _generate_mock_data(self) -> List[Dict[str, Any]]:
        """
        ç”Ÿæˆæ¨¡æ‹Ÿè½®æ’­å›¾æ•°æ®ï¼ˆå½“æ— æ³•å®é™…çˆ¬å–æ—¶ä½¿ç”¨ï¼‰
        """
        mock_slides = [
            {
                "image_url": "https://developer.huawei.com/images/carousel/slide1.jpg",
                "title": "HarmonyOS 4.0 å‘å¸ƒ",
                "subtitle": "å…¨åœºæ™¯æ™ºèƒ½ä½“éªŒ",
                "description": "å…¨æ–°ä¸€ä»£æ“ä½œç³»ç»Ÿï¼Œå¸¦æ¥æ›´æ™ºèƒ½çš„å…¨åœºæ™¯ä½“éªŒ",
                "all_text": ["HarmonyOS", "4.0", "å…¨åœºæ™¯", "æ™ºèƒ½ä½“éªŒ"],
                "raw_text_content": "HarmonyOS 4.0 - å…¨åœºæ™¯æ™ºèƒ½ä½“éªŒ"
            },
            {
                "image_url": "https://developer.huawei.com/images/carousel/slide2.jpg",
                "title": "HMS Core 6.0",
                "subtitle": "å¼€æ”¾èƒ½åŠ›ï¼Œåˆ›æ–°æ— é™",
                "description": "ä¸ºå¼€å‘è€…æä¾›æ›´å¼ºå¤§çš„å¼€æ”¾èƒ½åŠ›å’ŒæœåŠ¡",
                "all_text": ["HMS Core", "6.0", "å¼€æ”¾èƒ½åŠ›", "åˆ›æ–°"],
                "raw_text_content": "HMS Core 6.0 - å¼€æ”¾èƒ½åŠ›ï¼Œåˆ›æ–°æ— é™"
            },
            {
                "image_url": "https://developer.huawei.com/images/carousel/slide3.jpg",
                "title": "AIèƒ½åŠ›å¼€æ”¾",
                "subtitle": "æ™ºèƒ½æœåŠ¡ï¼Œè§¦æ‰‹å¯åŠ",
                "description": "åä¸ºAIèƒ½åŠ›å…¨é¢å¼€æ”¾ï¼ŒåŠ©åŠ›å¼€å‘è€…åˆ›æ–°",
                "all_text": ["AI", "èƒ½åŠ›å¼€æ”¾", "æ™ºèƒ½æœåŠ¡", "åˆ›æ–°"],
                "raw_text_content": "AIèƒ½åŠ›å¼€æ”¾ - æ™ºèƒ½æœåŠ¡ï¼Œè§¦æ‰‹å¯åŠ"
            }
        ]
        return mock_slides

    def _process_carousel_data(self, raw_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        å¤„ç†å’Œæ ‡å‡†åŒ–è½®æ’­å›¾æ•°æ®
        """
        if not raw_data:
            logger.warning("âš ï¸ åŸå§‹è½®æ’­å›¾æ•°æ®ä¸ºç©º")
            return []

        processed_data = []
        for i, slide in enumerate(raw_data):
            try:
                # æ ‡å‡†åŒ–æ•°æ®æ ¼å¼
                processed_slide = self._normalize_slide_data(slide, i + 1)
                if processed_slide:
                    processed_data.append(processed_slide)

            except Exception as e:
                logger.error(f"âŒ å¤„ç†è½®æ’­å›¾æ•°æ®ç¬¬ {i+1} é¡¹å¤±è´¥: {e}")
                continue

        logger.info(f"ğŸ“Š æ•°æ®å¤„ç†å®Œæˆï¼ŒåŸå§‹æ•°æ®: {len(raw_data)}ï¼Œæœ‰æ•ˆæ•°æ®: {len(processed_data)}")
        return processed_data

    def _normalize_slide_data(self, slide: Dict[str, Any], slide_number: int) -> Optional[Dict[str, Any]]:
        """
        æ ‡å‡†åŒ–å•ä¸ªè½®æ’­å›¾æ»‘å—æ•°æ®
        """
        try:
            # æå–å’ŒéªŒè¯å¿…å¡«å­—æ®µ
            slide_data = {
                "slide_number": slide_number,
                "image_url": self._validate_url(slide.get("image_url", "")),
                "title": self._clean_text(slide.get("title", "")),
                "subtitle": self._clean_text(slide.get("subtitle", "")),
                "description": self._clean_text(slide.get("description", "")),
                "all_text": self._clean_text_list(slide.get("all_text", [])),
                "raw_text_content": self._clean_text(slide.get("raw_text_content", "")),
                "crawl_timestamp": time.time()
            }

            # éªŒè¯æ•°æ®è´¨é‡
            if self._validate_slide_data(slide_data):
                return slide_data
            else:
                logger.warning(f"âš ï¸ è½®æ’­å›¾æ»‘å— {slide_number} æ•°æ®è´¨é‡ä¸è¾¾æ ‡ï¼Œå·²è¿‡æ»¤")
                return None

        except Exception as e:
            logger.error(f"âŒ æ ‡å‡†åŒ–è½®æ’­å›¾æ»‘å— {slide_number} æ•°æ®å¤±è´¥: {e}")
            return None

    def _validate_url(self, url: str) -> str:
        """
        éªŒè¯å’Œæ ‡å‡†åŒ–URL
        """
        if not url or not isinstance(url, str):
            return ""

        url = url.strip()
        if not url.startswith(("http://", "https://")):
            if url.startswith("//"):
                url = "https:" + url
            elif url.startswith("/"):
                url = self.config.base_domain + url
            else:
                url = self.config.base_domain + "/" + url

        return url

    def _clean_text(self, text: str) -> str:
        """
        æ¸…ç†æ–‡æœ¬
        """
        if not text or not isinstance(text, str):
            return ""

        # ç§»é™¤å¤šä½™ç©ºç™½å­—ç¬¦
        text = re.sub(r'\s+', ' ', text.strip())
        return text

    def _clean_text_list(self, text_list: List[str]) -> List[str]:
        """
        æ¸…ç†æ–‡æœ¬åˆ—è¡¨
        """
        if not text_list or not isinstance(text_list, list):
            return []

        cleaned_list = []
        for text in text_list:
            cleaned_text = self._clean_text(text)
            if cleaned_text and len(cleaned_text) > 2:  # è¿‡æ»¤æ‰å¤ªçŸ­çš„æ–‡æœ¬
                cleaned_list.append(cleaned_text)

        # å»é‡
        return list(dict.fromkeys(cleaned_list))

    def _validate_slide_data(self, slide_data: Dict[str, Any]) -> bool:
        """
        éªŒè¯è½®æ’­å›¾æ»‘å—æ•°æ®è´¨é‡
        """
        # è‡³å°‘è¦æœ‰å›¾ç‰‡æˆ–æ–‡æœ¬å†…å®¹
        has_image = bool(slide_data.get("image_url"))
        has_text = bool(
            slide_data.get("title") or
            slide_data.get("subtitle") or
            slide_data.get("description") or
            slide_data.get("all_text")
        )

        return has_image or has_text

    @log_function_call
    def validate_carousel_data(self, carousel_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        éªŒè¯è½®æ’­å›¾æ•°æ®é›†
        """
        if not carousel_data:
            logger.warning("âš ï¸ è½®æ’­å›¾æ•°æ®é›†ä¸ºç©º")
            return []

        valid_data = []
        for i, slide in enumerate(carousel_data):
            try:
                if self._validate_slide_data(slide):
                    valid_data.append(slide)
                else:
                    logger.warning(f"âš ï¸ è½®æ’­å›¾æ•°æ®ç¬¬ {i+1} é¡¹éªŒè¯å¤±è´¥ï¼Œå·²è¿‡æ»¤")

            except Exception as e:
                logger.error(f"âŒ éªŒè¯è½®æ’­å›¾æ•°æ®ç¬¬ {i+1} é¡¹å¤±è´¥: {e}")

        logger.info(f"ğŸ“Š è½®æ’­å›¾æ•°æ®éªŒè¯å®Œæˆï¼ŒåŸå§‹: {len(carousel_data)}ï¼Œæœ‰æ•ˆ: {len(valid_data)}")
        return valid_data

    def get_data_quality_report(self, carousel_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š
        """
        if not carousel_data:
            return {
                "total_items": 0,
                "quality_score": 0,
                "items_with_images": 0,
                "items_with_text": 0,
                "items_with_both": 0
            }

        total_items = len(carousel_data)
        items_with_images = sum(1 for item in carousel_data if item.get("image_url"))
        items_with_text = sum(1 for item in carousel_data if (
            item.get("title") or
            item.get("subtitle") or
            item.get("description") or
            item.get("all_text")
        ))
        items_with_both = sum(1 for item in carousel_data if (
            item.get("image_url") and (
                item.get("title") or
                item.get("subtitle") or
                item.get("description") or
                item.get("all_text")
            )
        ))

        # è®¡ç®—è´¨é‡åˆ†æ•°ï¼ˆ0-100ï¼‰
        quality_score = ((items_with_images + items_with_text) / (2 * total_items)) * 100

        return {
            "total_items": total_items,
            "quality_score": round(quality_score, 2),
            "items_with_images": items_with_images,
            "items_with_text": items_with_text,
            "items_with_both": items_with_both,
            "image_coverage": round((items_with_images / total_items) * 100, 2),
            "text_coverage": round((items_with_text / total_items) * 100, 2),
            "complete_coverage": round((items_with_both / total_items) * 100, 2)
        }

    async def crawl_with_retry(self, max_retries: int = None) -> List[Dict[str, Any]]:
        """
        å¸¦é‡è¯•æœºåˆ¶çš„å¼‚æ­¥çˆ¬å–
        """
        if max_retries is None:
            max_retries = getattr(settings, 'crawler_retry_count', 3)

        for attempt in range(max_retries + 1):
            try:
                if attempt > 0:
                    logger.info(f"ğŸ”„ ç¬¬ {attempt} æ¬¡é‡è¯•çˆ¬å–è½®æ’­å›¾æ•°æ®")
                    # æ·»åŠ å»¶è¿Ÿ
                    await asyncio.sleep(getattr(settings, 'crawler_delay', 5) * attempt)

                # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥çˆ¬è™«
                loop = asyncio.get_event_loop()
                carousel_data = await loop.run_in_executor(
                    self.thread_pool,
                    self.crawl_carousel_data
                )

                if carousel_data:
                    logger.info(f"âœ… çˆ¬å–æˆåŠŸï¼Œè·å– {len(carousel_data)} æ¡è½®æ’­å›¾æ•°æ®")
                    return carousel_data
                else:
                    logger.warning(f"âš ï¸ çˆ¬å–è¿”å›ç©ºæ•°æ®ï¼Œå°è¯• {attempt + 1}/{max_retries + 1}")

            except Exception as e:
                logger.error(f"âŒ çˆ¬å–å¤±è´¥ï¼Œå°è¯• {attempt + 1}/{max_retries + 1}: {e}")
                if attempt == max_retries:
                    logger.error("âŒ æ‰€æœ‰é‡è¯•å°è¯•éƒ½å·²å¤±è´¥")
                    return []

        return []

    async def test_crawler_connectivity(self) -> Dict[str, Any]:
        """
        æµ‹è¯•çˆ¬è™«è¿æ¥æ€§
        """
        test_result = {
            "target_url": self.config.target_url,
            "base_domain": self.config.base_domain,
            "timestamp": time.time()
        }

        try:
            # ç®€å•çš„è¿æ¥æµ‹è¯•
            response = requests.get(
                self.config.target_url,
                timeout=getattr(settings, 'crawler_timeout', 30),
                headers={"User-Agent": self.config.user_agent}
            )

            test_result["status"] = "success" if response.status_code == 200 else "warning"
            test_result["http_status"] = response.status_code
            test_result["response_time"] = response.elapsed.total_seconds()

        except Exception as e:
            test_result["status"] = "failed"
            test_result["error"] = str(e)

        return test_result

    def get_crawler_info(self) -> Dict[str, Any]:
        """
        è·å–çˆ¬è™«ä¿¡æ¯
        """
        return {
            "config": {
                "target_url": self.config.target_url,
                "base_domain": self.config.base_domain,
                "user_agent": self.config.user_agent,
                "viewport": {
                    "width": self.config.viewport_width,
                    "height": self.config.viewport_height,
                    "device_scale_factor": self.config.device_scale_factor
                },
                "headless": self.config.headless,
                "timeout": self.config.timeout
            },
            "thread_pool_workers": self.thread_pool._max_workers,
            "crawler_version": "1.0.0"
        }

    def __del__(self):
        """
        æ¸…ç†èµ„æº
        """
        try:
            if hasattr(self, 'thread_pool'):
                self.thread_pool.shutdown(wait=True)
        except Exception:
            pass


# å…¨å±€æœåŠ¡å®ä¾‹
_carousel_service: Optional[CarouselCrawlerService] = None


def get_carousel_service() -> CarouselCrawlerService:
    """
    è·å–è½®æ’­å›¾çˆ¬è™«æœåŠ¡å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
    """
    global _carousel_service
    if _carousel_service is None:
        _carousel_service = CarouselCrawlerService()
        logger.info("ğŸ¯ è½®æ’­å›¾çˆ¬è™«æœåŠ¡å®ä¾‹å·²åˆ›å»º")
    return _carousel_service